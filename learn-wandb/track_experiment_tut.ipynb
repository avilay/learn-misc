{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB\n",
    "This notebook shows a very basic usage of wandb to log ML runs. There are three heirarchy levels for logging -\n",
    "```\n",
    "entity\n",
    "    project\n",
    "        run (aka experiment)\n",
    "```\n",
    "\n",
    "The `entity` is usually the organization or team. In my case it is my username. Each `entity` can have many `project`s and each `project` can have many `run`s. A `run` is also referred to as an experiment in some of the documentation. I can log a bunch of things with wandb including matplotlib plots, histograms, images, etc. See [documentation for the `Run` object](https://docs.wandb.ai/ref/python/run).\n",
    "\n",
    "#### How to interpret parameter/gradient histogram\n",
    "Even though I have not explicitly named the layers in my model, PyTorch will give them default names. In this example the model has the following named parameters -\n",
    "```\n",
    "1.weight\n",
    "1.bias\n",
    "2.weight\n",
    "2.bias\n",
    "5.weight\n",
    "5.bias\n",
    "```\n",
    "\n",
    "When logging the histogram of these parameters (or their corresponding gradients), wandb uses the following naming scheme -\n",
    "`graph_{idx}{param_name}`\n",
    "\n",
    "**Refs**\n",
    "  * [wandb_watch.py:86](https://github.com/wandb/wandb/blob/722f9737ce1a77b8970fef275047e8a0f4a1a68e/wandb/sdk/wandb_watch.py#L86C45-L86C45)\n",
    "  * [wandb_torch.py:105](https://github.com/wandb/wandb/blob/07051ce76e01d3e30cf3b25b42c22cd94cf62f5f/wandb/wandb_torch.py#L105)\n",
    "\n",
    "The `idx` is a global variable in wandb and can be anything. This results in funny chart names like `graph51.bias`, where the `idx = 5` and `1.bias` is the param name.\n",
    "\n",
    "![parameters](./parameters.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = t.device(\"mps\")\n",
    "DATAROOT = Path.home()/\"mldata\"/\"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparams:\n",
    "    n_epochs: int\n",
    "    batch_size: int\n",
    "    dropout: float\n",
    "    lr: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout: float) -> t.nn.Module:\n",
    "    return t.nn.Sequential(\n",
    "        t.nn.Flatten(),\n",
    "        t.nn.Linear(28*28, 256),\n",
    "        t.nn.BatchNorm1d(256),\n",
    "        t.nn.ReLU(),\n",
    "        t.nn.Dropout(dropout),\n",
    "        t.nn.Linear(256, 10)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(is_train: bool, batch_size: int, slice = 5):\n",
    "    full_dataset = MNIST(\n",
    "        root=DATAROOT, \n",
    "        train=is_train, \n",
    "        transform=ToTensor(), \n",
    "        download=True\n",
    "    )\n",
    "    sub_dataset = Subset(\n",
    "        full_dataset, \n",
    "        indices=range(0, len(full_dataset), slice)\n",
    "    )\n",
    "    return DataLoader(\n",
    "        dataset=sub_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True if is_train else False, \n",
    "        pin_memory=True, num_workers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_image_table(tablename, images, predicted, labels, probs):\n",
    "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
    "    # üêù Create a wandb Table to log images, labels and predictions to\n",
    "    table = wb.Table(\n",
    "        columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(10)]\n",
    "    )\n",
    "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
    "        table.add_data(wb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
    "    wb.log({f\"{tablename}\":table}, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, valdl, loss_fn, epoch=0, batch_idx=0, log_images=False):\n",
    "    losses = []\n",
    "    corrects = []\n",
    "    totals = []\n",
    "\n",
    "    model.eval()\n",
    "    with t.inference_mode():\n",
    "        for i, (inputs, targets) in enumerate(valdl):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, targets).item()\n",
    "            losses.append(loss)\n",
    "            \n",
    "            preds = t.argmax(outputs, dim=1)\n",
    "            correct = (preds == targets).sum().item()            \n",
    "            corrects.append(correct)\n",
    "            totals.append(len(targets))\n",
    "\n",
    "            # If I don't give the table name then the tables keep getting\n",
    "            # overwritten with every new eval epoch. I can give each epoch's\n",
    "            # table a different name like shown below, but the rendering on\n",
    "            # wandb is not very good. see \n",
    "            # https://wandb.ai/avilay/learn-wandb-exp/runs/ssdqommr?workspace=user-avilay\n",
    "            # BEST PRACTICE: Just log the images for the last eval run.\n",
    "            if i == batch_idx and log_images:\n",
    "                log_image_table(\n",
    "                    f\"epoch-{epoch}\",\n",
    "                    inputs[:5],\n",
    "                    preds[:5],\n",
    "                    targets[:5],\n",
    "                    outputs[:5].softmax(dim=1)\n",
    "                )\n",
    "    avg_loss = t.mean(t.tensor(losses)).item()\n",
    "    avg_acc = (t.sum(t.tensor(corrects)) / t.sum(t.tensor(totals))).item()\n",
    "    wb.log({\n",
    "        \"val/loss\": avg_loss,\n",
    "        \"val/Accuracy\": avg_acc\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(dropout=0.25)\n",
    "model.to(DEVICE)\n",
    "valdl = build_dataloader(is_train=False, batch_size=100)\n",
    "loss_fn = t.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model, valdl, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del valdl\n",
    "del loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, traindl, loss_fn, optim, start_step=0, log_freq=1):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    with t.enable_grad():\n",
    "        for step, batch in enumerate(tqdm(traindl)):\n",
    "            images = batch[0].to(DEVICE)\n",
    "            targets = batch[1].to(DEVICE)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            losses.append(loss.detach().item())\n",
    "            if (start_step + step) % log_freq == 0:\n",
    "                avg_loss = t.mean(t.tensor(losses)).item()\n",
    "                wb.log({\n",
    "                    \"train/loss\": avg_loss\n",
    "                }, step=(start_step + step))\n",
    "                losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/avilay/projects/bitbucket/learn/learn-libs/learn-wandb/wandb/run-20231228_012429-5mrlvotm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/avilay/learn-wandb-basic/runs/5mrlvotm' target=\"_blank\">eager-paper-3</a></strong> to <a href='https://wandb.ai/avilay/learn-wandb-basic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/avilay/learn-wandb-basic' target=\"_blank\">https://wandb.ai/avilay/learn-wandb-basic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/avilay/learn-wandb-basic/runs/5mrlvotm' target=\"_blank\">https://wandb.ai/avilay/learn-wandb-basic/runs/5mrlvotm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:06<00:00, 55.12it/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:07<00:00, 52.60it/s] \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 375/375 [00:07<00:00, 49.26it/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda2c553a4ed4636b5a40085a3cd0dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.8245614035087719, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/Accuracy</td><td>‚ñÅ‚ñá‚ñà</td></tr><tr><td>val/loss</td><td>‚ñà‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>0.1464</td></tr><tr><td>val/Accuracy</td><td>0.9445</td></tr><tr><td>val/loss</td><td>0.16845</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-paper-3</strong> at: <a href='https://wandb.ai/avilay/learn-wandb-basic/runs/5mrlvotm' target=\"_blank\">https://wandb.ai/avilay/learn-wandb-basic/runs/5mrlvotm</a><br/>Synced 6 W&B file(s), 1 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231228_012429-5mrlvotm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = Hyperparams(\n",
    "    n_epochs=3,\n",
    "    batch_size=32,\n",
    "    dropout=0.2,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "run = wb.init(\n",
    "    project=\"learn-wandb-basic\",\n",
    "    config=asdict(hparams)\n",
    ")\n",
    "\n",
    "model = build_model(dropout=hparams.dropout)\n",
    "model.to(DEVICE)\n",
    "\n",
    "traindl = build_dataloader(is_train=True, batch_size=hparams.batch_size)\n",
    "valdl = build_dataloader(is_train=False, batch_size=100)\n",
    "\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optim = t.optim.AdamW(model.parameters(), lr=hparams.lr)\n",
    "steps_per_epoch = len(traindl)\n",
    "\n",
    "wb.watch(model, loss_fn, log=\"all\", log_freq=100)\n",
    "\n",
    "for epoch in range(hparams.n_epochs):\n",
    "    train(model, traindl, loss_fn, optim, start_step=steps_per_epoch * epoch, log_freq=100)\n",
    "    eval(\n",
    "        model, \n",
    "        valdl, \n",
    "        loss_fn, \n",
    "        epoch=epoch, \n",
    "        log_images=True if epoch == hparams.n_epochs - 1 else False\n",
    "    )\n",
    "\n",
    "wb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): ReLU()\n",
       "  (4): Dropout(p=0.2, inplace=False)\n",
       "  (5): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight torch.Size([256, 784])\n",
      "1.bias torch.Size([256])\n",
      "2.weight torch.Size([256])\n",
      "2.bias torch.Size([256])\n",
      "5.weight torch.Size([10, 256])\n",
      "5.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
